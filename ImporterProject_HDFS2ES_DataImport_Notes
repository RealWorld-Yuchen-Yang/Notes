1. app entry
    search/importer/src/main/java/com/yiche/bigdata/search/ImporterApplication.java
    git clone http://gitlab.bitautotech.com/groups/BDC/PLAT?non_archived=true&sort=latest_activity_desc

2. 使用chrome extension "Sense" (那个绿色的标) 可以观察ES中的数据：键值对

3. Apacche HDFS -- (spart) --> ES 文档
    https://www.elastic.co/guide/en/elasticsearch/hadoop/current/spark.html
  3.1 HDFS中信息可以从HUE中进行查询
  3.2 ES中索引可以从Chrome Extension：Sense进行查询
  3.3 功能是否实现我需要验证
    命令：
      1. GET history_index.*/_search //对history_index.*匹配的表的查询， 其返回值
          "_index": "history_index.2017-06-01", //相当于数据库中的数据库名
          "_type": "dm_autoreport_app_traffic", //相当于数据库中的表名
          "_id": "AVy0BCxaLdHqfUGDhbEO",
          "_score": 1,
          "_source": { //相当于数据库的schema
              "/metric/pv/dm_autoreport_app_traffic": 0,
              "/metric/new_user/dm_autoreport_app_traffic": 47641,
              "/dimen/product_type": 10022,
              "/dimen/dateTime": "2017-06-01",
              "/metric/uv/dm_autoreport_app_traffic": 980052
          }
      2. 查询某个数据库的schema
         如 history_index.2017-06-01
         GET history_index.2017-06-01/dm_autoreport_app_traffic/_mapping， 其返回值
          {
             "history_index.2017-06-01": {
                "mappings": {
                   "dm_autoreport_app_traffic": {
                      "dynamic": "false",
                      "_all": {
                         "enabled": false
                      },
                      "properties": {
                         "/dimen/dateTime": {
                            "type": "date",
                            "format": "yyyy-MM-dd"
                         },
                         "/dimen/product_type": {
                            "type": "integer"
                         },
                         "/metric/new_user/dm_autoreport_app_traffic": {
                            "type": "long"
                         },
                         "/metric/pv/dm_autoreport_app_traffic": {
                            "type": "long"
                         },
                         "/metric/uv/dm_autoreport_app_traffic": {
                            "type": "long"
                         }
                      }
                   }
                }
             }
          }

    3.4.1 索引的type域是否有值
    3.4.2 相应的mapping文件是否存在

4. Importer需求：使用scala操作java进行导数

5. 码表， 字典表，identity map指的都是一个东西

6. 我应该
  6.1 使用表名获取元数据信息
  6.2 从元数据的Info中提取信息，用于验证
  6.3 根据是否需要validate，怕端是否需要验证
  6.4 原来项目的最终任务是：
        编写Hadoop
          map 任务， 即将表中的一条数据，经过拼装HQL，写成json数据
          reduce 任务是调用插件执行的，所以不用我关心

7. 可以学习： 如何使用Elasticsearch的DSL

8. 原有Importer项目的文档
    http://172.20.4.40:8090/pages/viewpage.action?pageId=2785320

9. 原有工程的Debug Configuration
    在Intellij中的Debug Configuration中
    main class:
      com.yiche.bigdata.search.ImporterApplication
    program arguments:
      -add --ptTime="2017-08-13" --tableNames="bdc_index_dm.index_professional_dm_know_traffic_day, bdc_index_dm.index_professional_dm_action_leads_day"

10. 元数据MySql的配置地址为
      192.168.70.145:3306
      username:
        report
      password:
        report
      使用report数据库

11. 可以在application.properties中配置是否为test

12. 将原来的Importer功能重新在spark-importer中实现一遍

13. 我下载的测试数据
      hdfs地址： / user/ hive/ warehouse/ common.db/ dw_business_leads_base/ pt=2015-01-01
      下载地址：~/Downloads/000000_0

14.Sense SL:
      GET bdc_at_dm.db*/_search

15. 开发环境的 hadoop集群（里面安装了spark）， 其中一个节点 http://wiki.bitautotech.com/display/BDCPLAT/hadoop
    这个环境中的数据库于使用HUE访问的数据库时一个

      host： 192.168.15.46
      username： root
      password： 321.abc
    在开发环境上执行：
    $ hive, 便可进入hive的interactive shell
    之后执行HiveQL就和SQL没有区别了
    示例工程： http://gitlab.bitautotech.com/BDC/PLAT/bitauto_praise

16. testing command
      java -jar         -add --ptTime="2017-08-13" --tableNames="bdc_index_dm.dm_autotracking_app_auto_behaviour_uv_d, bdc_index_dm.index_professional_dm_action_leads_day"

17. to resolve java & scala together compile error
  17.1 $ mvn clean
  17.2 $ mvn scala:compile compile
  17.3 $ mvn package

18. 我可以使用的数据库为 （--ptTime=2017-08-01 ~ --ptTime=2017-08-31）
      bdc_index_dm
    表：
      index_professional_dm_know_traffic_day,
      index_professional_dm_know_traffic_page_day,
      index_professional_dm_action_leads_day,
      index_professional_dm_marketing_online_day,
      index_professional_dm_interest_contrast

19. spark-submit sample command
    在开发环境的机器里可以直接输入
  19.1 运行
    19.1.1 run on hadoop cluster
      192.168.70.141:9200
      spark-submit --proxy-user hive --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-08-01" --tableNames="yiche_pcwap.app_leads_channel_day"
      spark-submit --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-08-01" --tableNames="yiche_quote.app_leads_channel_day"
      spark-submit --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-08-01" --tableNames="yiche_app.app_leads_channel_day"

      spark-submit --proxy-user hive --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-08-01" --tableNames="yiche_app.app_leads_channel_day"
      spark-submit --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-10-19" --tableNames="yiche_pcwap.app_leads_channel_day"

      yiche_quote.app_leads_channel_day

20. 真正执行的任务为map-reduce job
    我们组的map-reduce任务队列为：
      "mapreduce.job.queuename", "root.bdc.da"

21. spark任务执行记录
      http://192.168.15.46:18088

22. 在Elasticsearch中验证结果
    DELETE bitauto_index_day
    GET bitauto_index_day/index_professional_dm_know_traffic_page_day/_search

23. 测试表
      报价大全：yiche_quote.app_leads_channel_day //permission denied 64 rows done
      易车app：yiche_app.app_leads_channel_day // 64 rows, done
      pc/wap：yiche_pcwap.app_leads_channel_day // 36 rows, done

24. 在MIS系统中， key是ES中的数据， 但是它的值反映了field在Hive数据库中的存储结构
     mapping指定了es中的字段对应Hive中的字段

25. 检查Elasticsearch中document导入是否成功
    使用Chrome插件Sense访问：192.168.70.141:9200
      GET app_leads_channel_day_index/yiche_pcwap.app_leads_channel_day/_search
      GET yiche_quote_index/yiche_quote.app_leads_channel_day/_search
      GET yiche_app_index/yiche_app.app_leads_channel_day/_search

spark-submit --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-10-19" --tableNames="yiche_pcwap.app_leads_channel_day"

2017-08-31

yiche_quote.app_leads_channel_day
yiche_app.app_leads_channel_day
yiche_pcwap.app_leads_channel_day

验证mapping是否生成：
  GET app_leads_channel_day_index.*/yiche_pcwap__app_leads_channel_day/_mapping

spark-submit --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-10-15" --tableNames="yiche_pcwap.app_leads_channel_day" --ignoreMetadataRestrict=true --ptEqIndex=true --version=v3
spark-submit --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-10-19" --tableNames="yiche_quote.app_leads_channel_day" --ignoreMetadataRestrict=true --ptEqIndex=true --version=v3
spark-submit --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-01-01" --tableNames="yiche_app.app_leads_channel_day" --ignoreMetadataRestrict=true --ptEqIndex=true --version=v3

SELECT  pt from yiche_pcwap.app_leads_channel_day order by pt desc limit 1;


curl -i -H "Accept: application/json" -H "Content-Type: application/json" -X GET http://172.20.0.116:9003/resource

线上的查询elasticsearch命令
  curl -XGET 'http://172.20.0.116:9002/app_leads_channel_day_index.*/yiche_pcwap__app_leads_channel_day/_search'

26. 线上的spark任务执行workflow, pcwap表的导入任务配置在我的workflow:BI_data中
    spark任务是使用root执行的， 这个账户被触发是因为我们将脚本放在线上机器的root目录下

spark-submit --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-10-20" --tableNames="yiche_pcwap.app_leads_channel_day,yiche_quote.app_leads_channel_day,yiche_app.app_leads_channel_day" --ignoreMetadataRestrict=true --ptEqIndex=true --version=v3

2017-10-01
app_autoreport_app_business_month



spark importer "workflow" and "coordinator" 配置 （参考BI_data）
1. 在workflow中配置
  1.1 user and host: root@172.20.0.25
  1.2 ssh command /bitauto/shells/bi_dp/spark-es.sh
  1.3 arguments
    1.3.1 ${INPUT_DATE}
    1.3.2 yiche_app.app_leads_channel_day,yiche_quote.app_leads_channel_day,yiche_pcwap.app_leads_channel_day//即逗号分隔的表名
  1.4 在settings配置
    1.4.1 INPUT_DATE, ${coord:formatTime(coord:dateOffset(coord:nominalTime(), -1, 'MONTH'), 'yyyy-MM')}
    1.4.2 app_index_compare_make_nation_month_INPUT, /bitauto/sign/yiche_pcwap/app_index_compare_brand_nation_month/${YEAR}-${MONTH}/_SUCCESS (success path)
          注意，这里每个workflow操作几张表就要建几个depend on 的 _SUCCESS 标签
          逻辑相当于：所有需要导的表都存在的情况下，才进行导数操作

2. 在coordinator中配置调度信息
  2.1 设置时区为上海
  2.2 开始时间<每天任务调度时间<结束时间， 其中每天任务时间需要配置在8：30之后（数仓问题）
  2.3 传入INPUT_DATE, 表名对应的_success文件地址

spark-submit --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-10-31" --tableNames="yiche_easypass.app_autoreport_app_business_amount_month,bitauto_dm.app_autoreport_app_brand_ad_month,yiche_easypass.app_autoreport_app_business_month" --ignoreMetadataRestrict=true --ptEqIndex=true --version=v3
spark-submit --class  com.yiche.bigdata.search.SparkImporterApplication  --master yarn  --executor-memory 512M --queue root.bdc.dw /root/yyc/spark-importer-1.0-SNAPSHOT-assembly.jar -add --ptTime="2017-10-31" --tableNames="yiche_easypass.app_autoreport_app_business_month" --ignoreMetadataRestrict=true --ptEqIndex=true --version=v3
app_autoreport_app_business_month
yiche_easypass__app_autoreport_app_business_amount_month,bitauto_dm__app_autoreport_app_brand_ad_month,yiche_easypass__app_autoreport_app_business_month
