I. Hadoop Fundamentals
Meet Hadoop
1. HDFS: Hadoop Distributed Filesystem
2. MapReduce is a batch query processor
3. Hadoop works well with semi-structured and unstructured data
    Semi-structured data: though there may be a schema, it is often ignored. like spreadsheet (whose structure is a grid of cells)
    Unstructured data: does not have any particular internal structure. like plain text, image
4. Data locality: Hadoop tries to co-locate data with compute nodes.
                  so data access is fast because it is local
5. MapReduce is designed to run jobs that last minutes or hours on trusted, dedicated hardware running in a single data center
   with very high aggregate bandwidth
6. The map function is a good place to drop bad records.
7. Data Flow
  7.1 MapReduce job:
        unit of work that the client wants to be performed.
        consists of:
          7.1.1 input data
          7.1.2 MapReduce program
          7.1.3 configuration information
  7.2 Hadoop runs the job by dividing it into tasks:
    7.2.1 map tasks
    7.2.2 reduce tasks
  7.3 Tasks are scheduled using YARN (Yet Another Resource Negotiator)
      tasks are run on nodes in clusters
      if a task fails, it will be automatically rescheduled to run on a different node.
  7.4 splits:
        Hadoop divides the input to a MapReduce job into fixed-size pieces called input splits.
        Hadoop creates one map task for each split,
        which runs the user-defined map function for each record in the split
        A good split size tends to be the size of an HDFS block, which is 128MB by default
  7.5 Data locality optimization:
        Hadoop tries its best to run map tasks on the node where data originates
        (same node) > (same rack) > (different rack)
  7.6 Map tasks write their output to the local disk, for its output is intermediate result
  7.7 Reduce task to not have data locality -- input to a single reduce task is normally the output from **all** mappers
      for each HDFS block of the reduce output,
      the first replica is stored on the local node,
      with other replicas being stored on off-rack nodes for reliability
  7.8 When there are multiple reducers,
      the map tasks partition their output,
      each creating one partition for each reduce task.
      There can be many keys (and their associated values) in each partition,
      but the records for any given key are all in a single partition


The Hadoop Distributed System
1. 
