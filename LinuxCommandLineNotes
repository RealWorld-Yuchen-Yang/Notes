Navigation
  1. In Linux, filenames and commands are case sensitive

Exploring The System
  1. file
      determine file type
  2. ls
      list files of certain directory, can take multiple directories as input
  3. linux command line options:
      short version: -x
      long version: --x

Manipulating Files and Directories
  1. Wildcard:
    *, matches any character
    ?, matches any single character
    [characters], matches any character that is a member of the set characters
    [!characters], matches any character that is not a member of the set
    [[:class:]], matches any character that is a member of the specified class
      Commonly used character classes:
        [:alnum:], matches any alphanumeric character
        [:alpha:], matches any alphabetic character
        [:digit:], matches any numeral
        [:lower:], matches any lowercase letter
        [:upper:], matches any uppercase letter

  2. cp, copy files and directories.
    2.1 Useful options
      -a, --archive, copy the files and directories and all of their attributes, including ownerships and permissions
      -r, --recursive, recursively copy directories and their contents
      -u, --update, only copy files that either don't exist or are newer than the existing version
    2.2 example:
      cp -r dir1 dir2,
        copy the contents of directory dir1 to directory dir2.
        if directory dir2 does not exist, it is created

  3. mv, Move and rename files
    3.1 example:
      mv dir1 dir2,
        If directory dir2 does not exist, create directory dir2 and move the contents of
        directory dir1 into dir2 and delete directory dir1
        Note, here we do not need to declare "recursive" option
  4. ln, create links
    4.1 **ln file link**, create hard link
      4.1.1 meaning:
        by default, every file has a single hard link that gives the file its name.
        when we create a hard link, we create an additional directory entry for a file
        target and hard link's inode number(first field displayed by "ls -i") are the same, meaning they are the same file
        target and symbolic link's inode number are different
      4.1.2 limitations
        4.1.2.1 a hard link cannot reference a file outside its own file system(disk partition)
        4.1.2.2 a hard link cannot reference a directory
      4.1.3 explanation
        A hard link is indistinguishable from the file itself.
        And all hard links and its original's link count are the same
        Unlike a symbolic link, when you list a directory containing a hard link,
        you will see no special indication of the link.
        When a hard link is deleted, the link is removed but the contents of the file itself continue to exist.
        The file is deleted until all the links to the file are deleted

    4.2 **ln -s item link**, create symbolic link, where item is either a file or a directory
        when doing ls, the link will be shown as:
        **link -> item**,
        also the link is indicated as file type "l", which means link
      4.2.1 meaning:
        symbolic links were created to overcome the limitations of hard links.
        symbolic links work by creating a special type of file that contains a text pointer to the referenced file or directory
        it is the shortcut of the linked item
      4.2.2 creating:
        when creating symbolic link, you can either use absolute pathnames or relative pathnames.
        using "relative pathnames" is more useful, because it allows a directory containing symbolic links to be renamed/moved without breaking the links
      4.2.3 editing:
        editing contents will result in the original item
      4.2.4 deleting:
        deleting the symbolic link only deletes the link, not the original item.
        if the target is deleted before the link, the link is said to be broken.

Redirection
1.
   1.1 COMMANDS > FILE, redirect standard output to a file from the beginning
   1.2 COMMANDS >> FILE, redirect standard output to a file by appending the content at the end
   1.3 COMMANDS 2>, or 2>> FILE, are used to redirect standard error,
   1.4
       COMMANDS > FILE 2>&1, redirects both stdOutput and stdError to a FILE
        or
       COMMANDS &> FILE
        or
       COMMANDS &>> FILE
  Note: the file descriptors as: stdInput(0), stdOutput(1), stdError(2)
        Also, redirection operator silently creates or overwrite files


2. silently discards outputs or errors to location: /dev/null
   e.g. COMMAND > /dev/null

3. cat, read and copy file to stdOutput
  Note: in absence of filename arguments, cat copies standard input to standard output
        which can be used to create short files
        e.g. cat > FILE,
        then beginning typing, use 'ctl+d' to end the input

4. INPUT SOURCE < FILE, change the input source from stdInput to be FILE

5. pipeline filters are: sort, uniq

6. wc, Word Count, prints #lines, #words, #bytes

7. grep PATTERN,
      -i, ignore case
      -v, do not match PATTERN

8. tee, read from stdin and output to both stdout and 0~* files
  This is useful for capturing a pipeline's contents at an intermediate stage of processing

Seeing the World as the Shell Sees It
1. Shell arithmetic expressions:  $((expression))

2. Brace expansions: echo {PATTERN{NESTED_PATTERN}}

3. echo $VARIABLE_NAME, print variable value, which is parameter expansion

4. Command Substitution, allow user to use output of a command as an expansion
   Syntax: $(COMMAND_WITH_ARGUMENTS) or older version 'COMMAND_WITH_ARGUMENTS'

5.Quoting:
  5.1 Double Quote " ", text inside double quotes, all special characters used by the shell lose their special meaning
      Exceptions are: "$", "\", and "'"
      This means that in double quote
        5.1.1 word-splitting, pathname expansion, ~tilde expansion and brace expression are suppressed
        5.1.2 parameter expansion, arithmetic expansion and command substitution are still carried out
  5.2 Single Quote ' ', all expansions are escaped inside single quote

6. Escaping:
  6.1 inside "Double Quotes", we can use \ to escape special meaning characters
  6.2 It is possible to use characters in filenames that normally have special meaning.
      say, "$", "!", "&", "\"
  6.3 backslash can be additionally used to escape control characters,
      say, "\a(Alert)", "\b(backspace)", "\n(new line)", "\r(carriage return)", "\t(tab)"

Advanced Keyboard Tricks
1. Cursor movement:
  1.1 ctrl+a, move to the beginning of the line
  1.2 ctrl+e, move to the end of the line

2. Cut and paste
  2.1 ctrl+k, kill text from cursor location to the end of line
  2.2 ctrl+u, kill text from cursor location to the beginning of line
  2.3 ctrl+y, paste text from terminal buffer to the terminal

3. History reverse incremental search: ctrl+r, then enter the text you are looking for
   Once find the command,
    3.1 press "ENTER" to execute
    3.2 press ctrl+j, to copy the line from history to the current command line
    3.3 press ctrl+r, to find the next occurrence of the text(move up the history list)
    3.4 press ctrl+c, to end the searching

4. script [FILE_NAME], used to record session command into a shell script file FILE_NAME
   type "exit" to end the recording

Permissions
1. su, run a shel as another user, password is the other user's password

2. sudo, execute a command as another user, password is the current user's password
   The sudo command allows an administrator to set up a configuration file called /etc/sudoers,
   and define specific commands that particular users are permitted to execute under an assumed identity
   The choice of which command to use is largely determined by the Linux distribution

3. /etc/shadow, holds information about the user's password

4. a symbolic's accessibility(file mode) is always "rwxrwxrwx", which is a dummy value
   the actual accessibility is determined by the file that the link is pointing to.

5. program files written in scripting languages must also be set as readable to be executed,
   so the file mode of scripts to be executed should be as least r-x

6. umask [XXXX], view|set the default permissions
   XXXX are octal values,
   after expending the octal digits into binary,
   where 1 appears in the mask, the corresponding permission is removed

7. Typical tasks requires super user priviledge
   * installing and updating software
   * editing system configuration files
   * accessing devices

   Processes
     1. Zombie process: This is a child process that has terminated, but has not been cleaned up by its parent

     2. Shell prompt is not returned, because the shell is waiting for the program to finish

     3. If we want to get the shell prompt back without terminating the program,
        we should place the program in the background,
        while "terminal" is regarded as the foreground.

     4. jobs, list jobs launched from the terminal

     5. fg %#JOB, WILL bring the job back to the foreground

     6. ctrl+z (TSTP,terminal stop, 20), will stop(pause) a job.
        signal STOP(19), is the corresponding stop signal to the kernel

     7. move the stopped job to background and let it run: bg %#JOB
        move the stopped job to the foreground and let it run: fg %#JOB
        Note: I can not move a foreground job to the background without stopping it

     8. The benefit of launching a program from CLI instead of from GUI is
        in this way, we can view the program's error messages

     9. There are two levels of signals
       9.1 signal to the Kernel, this is done mandatory
       9.2 signal to the program/Terminal, the program will decide how to deal with the signal

     10. kill's default signal is TERM(Terminate, 15)

     11. continue(18), restore a process after stopping it.

     12. kill -l, will list all signals

     13. I must have super user's priviledge to kill other people's process

     14. pstree, display a tree of all processes

   Environment
     1. Environment contents:
       1.1 environment variable
       1.2 shell variables
       1.3 alias
       1.4 shell functions

     2. To view the environment
       2.1 set, view both shell and environment variables
       2.2 printenv, view only the environment varialbes

     3. To use the environment variable, use the VARIABLE_NAME directly,
        To use the value of the environment variable, use $VARIABLE_NAME
        i.e view environment variable value: echo $VARIABLE_NAME

     4. shell script comments: #LINE

     5. environment path is stored in PATH variable, and separated by ":"

     6. export PATH, tells the shell to make contents of PATH to child processes of this shell

     7. Using nano editor, "control commands" are issued by ctrl+KEY
       7.1 ctrl+x, exit
       7.2 ctrl+o, save

   Introduction to VI(VIM)
     1. :q, gently quit VIM
        :q!, force quit VIM

     2. If you are lost in VIM, press ESC twice to focus

     3. The leading "~" character indicates no text exists on the line

     4. When starting up VIM, we firstly enters the command mode

     5. In command mode, enter "i", to enter insert mode. (Note: there is no leading ":" here)

     6. Press ESC in insert mode, will let the user go back to command mode

     7. In command mode
       7.1 enter ":w", will save the file
       7.2 enter ":wq", will save the file and quit VIM

     8. Usually, command#, will execute the command # times

     9. In command mode, press "u" will undo the last change

     10. In command mode,
       10.1 press "a", append at the next character
       10.2 press "A(shift+a)", append at the end of current line

     11. In command mode,
       11.1 o, enter a new line before the current line
       11.2 O, enter a new line after the current line

     12. In command mode, press "x" delete the current character

     13. Cursor moving anchors, they can either be used alone, or combined with editing commands
       13.1 ^, beginning of the current line
       13.2 $, end of the current line
       13.3 G, last line of the file

     14. d, cut commands
       14.1 dd, cut the current line
       14.2 d^, delete from the cursor to the first non-whitespace character in the line
       14.3 d$, delete from the cursor to the end of the current line

     15. y, copy(yank) commands

     16. p, paste

     17. j, join(it should be issued at the end of a line, and it will join the next line with the current line)

     18. /PATTERN, used to search in the entire file

     19. In command mode, switch from one file to another: press "n" or "N"
         Note, if the file is not saved, vi will prevent the user from switching

     20. In command mode, if we are modifying multiple files
       20.1 :buffers, list all the edited files
       20.2 :buffer #, switch to the #th buffer
       20.3 :e, open an additional file to the current edit session
       20.4 :r FILE, read in the whole FILE into the cursor position

Package Management
1. Packages can be installed in two ways
  1.1 Install from a repository by using high level tools like apt-get, yum, which will conduct dependency resolution
  1.2 Install from a package file by using low level tools like dpkg, rpm, which can be installed directly without dependency resolution

Storage Media
1. list all the mounted file systems:
    mount

2. mount a device;
   The first step in managing a storage device is attaching the device to the file system tree.
   This process is called mounting
   2.1 to actually mount/umount a device, we need the super user priviledge
   2.2 create a new mount point for the disk,
       which is usually a directory on the file system tree
   2.3 mount the device as a type of file system on the mounting point
       mount -t FILE_SYSTEM_TYPE DEVICE_NAME MOUNT_POINT
       i.e. mount -t iso9660(means CD-ROM) /dev/hdc /mnt/cdrom

3. umount a device
   To umount a device, we firstly need to make sure we are not using,
   which is by change the working directory out of the device's file system, then
   umount DEVICE_NAME,
   i.e. umount /dev/hdc
   Note: umounting a device entails writing all the remaining data to the device,
         so that it can be safely removed.
4. Linux Storage Device Names
  4.1 /dev/hd*#, represents IDE(PATA) disk on older systems, where
      *, master/slave device channel
      #, partition number on the device
      i.e. /dev/hda1 refers to the first partition on the first hard drive on hte system
                     /dev/hda refers to the entire drive
  4.2 /dev/sd*#, represents  SCSI disks on recent Linux systems
                kernel treats all disk like devices(including PATA/SATA hard disk, flash drives and USBs) as SCSI disks
  4.3 /dev/cdrom, /dev/dvd, /dev/floppy are symbolic links, which point to the actual device files

5. use "tail -f /var/log/messages" to determine which device has been plugged in. (or other system operations)

6. device name is determined during plug time.
   it will remain the same as long as it remains physically attached to the computer and the computer is not rebooted

Networking
1. ping, use ICMP(Internet Control Message Protocol)
2. tranceroute, output the route from the user's machine to the destination
3. netstat, used to examine various network settings and statics
4. FTP is not secure, they are not encrypted and anyone sniffing the network can see them.
   because of this, almost all FTP done over the Internet is done by anonymous FTP servers.
   Anonymous Server:
    login name: anonymous
    password: a meaningless password
5. wget, downloading content from both web and FTP sites
6. PuTTY is a Windows SSH client program
7. scp and sftp are similar, and are both used to transmit files over ssh port
  scp REMOTE_USER@REMOTE_HOST:REMOTE_DIRECTORY/REMOTE_FILE LOCAL_DIRECTORY:
  This results in copying the REMOTE_FILE TO the LOCAL_DIRECTORY

Searching for files
1. locate, find files by name

2. find, search for files in a directory hierarchy based solely on the file's name
  2.1 find can take 1~* directories as arguments

3. xargs, build and execute command lines from standard input
  the xargs command accepts input from standard input and converts it into an argument list for a specified command.


4. touch, change file times

5. stat, display file or file system status

Archiving and Backup
1. Compression programs
   Note: do not be copmressive complusive, compress the already compressed files additionally will only result in larger files
  1.1 gzip FILE, compress the FILE, and replace the original one
      gunzip FILE.gz, is the corresponding decompression operation
      gunzip -c TEXT_FILE.gz, view the contents of a compressed text file

  1.2 bzip2 FILE, block sorting file compressor, different from gzip by using different compression algorighm
                  output is FILE.bz2

2. archiving programs
    Archiving is the process of gathering up many files and bundling them together into a single large file.
    Archiving is often used with compression tasks
    files with extension .tar, indicates a plain tar archive
    files with extension .tgz, indicates a gzipped archive
  2.1 tar OPTIONS FILE/PATH_NAMES, tape archiving utility
    tar options:
      2.1.1 c, create an archive from a list of files and/or directories
      2.1.2 x, extract an archive
      2.1.3 r, append specified pathnames to the end of an archive
      2.1.4 t, list the contents of an archive
      2.1.5 f, specify the name of the tar archive
      2.1.6 v, verbose
      Note:
      1. tar's options do not have a leading dash (-)
      2. files and directories extracted from archives take the ownership of the user performing the restoration
      3. the default of pathnames is relative, rather than absolute, by simply removing any leading slash from the pathname
      4. using 'tar' with 'find' is a good way of creating incremental backups
         i.e. find DIRECTORY -name 'FILE_NAME' | tar cf - --files-from=- | gzip > OUTPUT_NAME.tgz
          * if the filename '-' is specified, it is taken to mean standard input or output as needed.
          * --files-from| -T, cause tar to read its list of pathnames from a file rather than the command line

  2.2 zip, package(archive) and compress files
           -r, recursive
      unzip, the corresponding decompression operation
           -l, cause unzip to merely list the contents of the archive without extracting the file.

3. rsync OPTIONS SOURCE DESTINATION, remote file and directory synchronization
  A common strategy for maintaining a backup copy of a system involves keeping one or more directories synchronized with another directory
  rsync  detect the differences between two directories and perform the minimum amount of copying required to bring them in sync.
  SOURCE and DESTINATIONJ are one of the following
  3.1 local file or directory
  3.2 remote file or directory(USER@HOST:REMOTE_DIRECTORY)
  3.3 a remote rsync server specified with a URI of rsync://[USER@]REMOTE_HOST[:PORT]REMOTE_DIRECTORY
  i.e. rsync -av SOURCE_DIRESCTORY DESTINATION_DIRECOTRY,
       this cause a mirror of the SOURCE_DIRECTORY to be made into DESTINATION_DIRECTORY
        -a, archiving
        -v, verbose
  i.e. sudo rsync -av --delete --rsh=ssh /LOCAL_DIRECTORIES REMOTE_HOST:REMOTE_DIRECTORY, use rsync to copy files over network
        --delete, remove files from destination if they do not exist on the source
        --rsh, remote shell specification

Regular Expression
1. grep(Global Regular Expression Print)
  grep [OPTIONS] regex [FILE], grep options:
  1.1 -i, ignore case
  1.2 -v, invert match, does not contain the regex pattern
  1.3 -c, count, print the number of matches
  1.4 -l, print the name of each file that contains a match of the lines themselves
  1.5 -L, print the name of each file that do not contain matches
  1.6 -n, prefix each matching line with the number of line within the files
  1.7 -h, for multi-file searches, suppress the output of filenames

2. Metacharacters and Literals
  Regular expression metacharacters consist of the following:
    ^, $, ., [ ], { }, -, ?, *, +, ( ), |, \
  Note: when passing regular expressions containing metacharacters on the command line,
        it is vital that they be enclosed in quotes to prevent the shell from attempting to expand them
  2.1 '.', used to match any one character

  2.2 '^', '$', anchors in regular expression, '^' represents the beginning of the line, '$' represents the end of the line
      Note: '^$' is used to match blank lines

  2.3 [ ], match one of the characters inside the [ ] bracket
      Note: metacharacters lose their special meaning when placed within bracket expressions.
            however, there are two cases:
              2.3.1 '^', be the first character in brackets, indicates negation, it is counted as one character and none of the characters in the bracket should be matched.
              2.3.2 '-', in brackets, indicates a character range,
                         also, by making '-' the first letter, we treat it as a literal '-'

  2.4 character classes
    2.4.1 [:alnum:], alphanumeric characters, [A-Za-z0-9]
    2.4.2 [:word:], [:alnum:] & '_'
    2.4.3 [:alpha:], [A-Za-z]
    2.4.4 [:digit:], [0-9]
    2.4.5 [:xdigit:], hexadecimal characters, [0-9A-Fa-f]
    2.4.6 [:blank:], space and tab
    2.4.7 [:space:], the whitespace characters including: space, tab, carriage return, newline, vertical tab, form feed. [ \t\r\n\v\f]
    2.4.8 [:cntrl:], ASCII control codes, include characters 0~31, 127
    2.4.9 [:graph:], ASCII code 33~126
    2.4.10 [:lower:], the lowercase letters
    2.4.11 [:upper:], the uppercase letters
    2.4.12 [:punct:], the punctuations, [-!"#$%&'()*,./:;<=>?@[\\\]_`{|}~"]
    2.4.13 [:print:], all the printable characters, [:graph:] & space

  2.5 in the extended grep feature, -E, '|' means logical or

  2.6 Quantifiers,
    Extended regular expressions support several ways to specify the number of times element is matched
    2.6.1 '?', 0/1 times
    2.6.2 '*', 0/more times
    2.6.3 '+', 1/more times
    2.6.4 {N}, exactly N times
          {N, M}, [N, M] times
          {N,}, no less than N times
          {,M}, no more than M times

Text Processing
1. cat, concatenate files and print on the standard output
  options:
    -A, display non-printing characters in the text
    -n, number lines
    -s, suppresses the output of multiple blank lines

2. sort, sort lines of text files
3. uniq, report or omit repeated lines
4. cut, remove sections from each line of files
5. paste, merge lines of files
6. join, join lines of two files on a common field
7. comm, compare two sorted files line by line
8. diff, compare files line by line
9. patch, apply a diff file to an original
  9.1 prepare diff: diff -Naur old_file new_file > diff_file
    -N, new file, treat absent files as empty
    -a, treat all files as text
    -u, Output NUM (default 3) lines of unified context.
    -r, recursive
  9.2 patch <diff_file
    Note: we do not need to specify the target file to patch,
          as the diff file (in unified format) already contains the filenames in the header.

10. tr, translate or delete characters
11. sed, stream editor for filtering and transforming text
12. aspell, interactive spell checker

Formatting Output
1. use:
  groff -mandoc > FILE, to generate a .ps file
2. additionally we can use
  ps2pdf PS_FILE PDF_FILE, to generate a pdf file out of the .ps file

Writing Shell Scripts
1. Three steps of writing a shell script
  1.1 write a shell script, name the script with .sh extension
      so as to give other programs like Atom the indication of the file type
  1.2 make the script executable, chmod +x SCRIPT
      Alternatively, there are two numbered permission types
      1.2.1 755, everyone can execute and read, only the owner can edit
      1.2.2 700, only the owner can execute.
  1.3 put the script somewhere the shell can find it
      PATH variable separate the each executable paths by using ":" as a separator
      In the ~/.bash_profile, or ~/.bash_rc
      export PATH=SHELL_SCRIPT_HOME:"$PATH"
      after the modification, we should issue . .bash_profile, where "." is the synonym of "source"
      Note: $VARIABLE can be included in " ", shell will do the expansion

2. Script File Format
  2.1 first line #!/bin/bash,
    this is the shebang, it is used to tell the system the name of the interpreter that should be used to execute the script that follows.

3. Good locations for scripts
  3.1 ~/bin, scripts intend for personal use.
  3.2 /usr/local/bin, scripts shared by all users on the system
  3.3 /usr/local/sbin, scripts for system administrators
  3.4 /usr/bin, scripts/compiled programs of locally supplied software

4. Tricks
  4.1 when interacting with shell directly, short options are preferred for the sake of less typing
      when writing shell scripts, long options are preferred for the sake of readability
  4.2 '\', used at the end of a script line, is used as line-continuation marker,
           which can increase readability

Starting a Project
1. variables and constants
  1.1 declare: VARIABLE=VALUE
      USE: $VARIABLE
  1.2 we also have access to shell variables, which we do not need to declare in the script
  1.3 declare read-only variables
    declare -r VARIABLE=VALUE

2. shell does not care about the type of variables,
   it treats them all as Strings

3. results of a command can be assigned to a variable
  VARIABLE=$(COMMAND)
  i.e. d=$(ls -l foo.txt)

4. multiple variable assignments may be done on a single line
  i.e. a=5 b="a string"

5. during expansion, VARIABLE_NAMEs may be surrounded by optional curly braces "{ }".
  This is useful in cases where a name becomes ambiguous due to surrounding context
  i.e. mv $filename ${filename}1
  by adding the surrounding braces,
  the shell no longer interprets the tailing 1 as part of the variable name,
  but only the ${filename} part of ${filename}1 will be expanded

6. Here document:
   it is used for I/O redirection,
   which embed a body of text into the shell script,
   and feed the embedded text into the standard input of a command

   Syntax:
    COMMAND <<- END_OF_LINE_TOKEN
    EMBEDDED_TEXT_BLOCK
    END_OF_LINE_TOKEN

   Note:
    6.1 END_OF_LINE_TOKEN can be any token,
        but by convention, it is usually _EOF_
    6.2 The '-' after << is used to let shell script ignore the leading tab characters in the embedded text, so as to improve readability
    6.3 inside the embedded text, the " or ' are escaped

Top-Down Design
1. Shell Functions
  1.1 We could write separate scripts and place them in a directory listed in the PATH
      Or, we could embed the functions within scripts
  1.2 Shell function's syntactic forms
    function NAME{
      COMMANDS
      return
    }

    or

    NAME(){
      COMMANDS
      return
    }
  1.3 Since shell scripts are executed in a top-down manner
      in order for function calls to be recognized as shell functions
      and not interpreted as the names of external programs,
      shell function definitions must appear in the script before they are called.

2. Local Variables
    the syntax for local variables is the same as global variables
    However, global variables are defined outside any function
    local variables are defined inside functions

Flow Control: Branching with if
1. "if then else" statement syntax
  if [COMMANDs1]; then
    COMMANDs2
  elif [COMMANDs3]; then
    COMMANDs4
  else
    COMMANDs5
  fi

  Note: [COMMANDs] is the text statement syntax

2. exit status of a command
  Once a command is issued, as a side effect
  it will update the $?, which represents the exit status of the previous command
  exit status ranges from 0 to 255
  0, successful
  1~255, different error codes, meaning can be find in man page

3. test statement
  syntax:
    test EXPRESSION
      or
    [EXPRESSION], which is more popular

4. File expressions
    file1 -ef file2, file1 and file2 have the same inode numbers(the two filenames refer to the same file by hard linking)
    file1 -nt file2, file1 is newer than file2
    file1 -ot file2, file2 is order than file2
    -b file, file exists and is a block-special (device) file
    -c file, file exists and is a character-special (device) file
    -d file, file exists and is a directory
    -e file, file exists
    -f file, file exists and is a regular file
    -g file, file exists and is set-group-ID
    -G file, file exists and is owned by the effective group ID
    -k file, file exists and has its "sticky bit" set.
    -L file, file exists and is a symbolic link
    -O file, file exists and is owned by the effective user ID
    -p file, file exists and is a named pipe
    -s file, file exists and has a length greater than zero
    -S file, file exists and is a network socket
    -t fd, fd is a file descriptor directed to/from the terminal.
           This can be used to determine whether standard input/output/error is setuid
    -u file, file exists and is setuid
    -r file, file exists and is readable (has readable permission for the effective user)
    -w file, file exists and is writable (has write permission for the effective user)
    -x file, file exists and is executable (has execute/search permission for the effective user)

5. have variable wrapped in quotes ensures that the operator is always followed by a string,
   even if the string is empty

6. exit, appearing on the last line of the script,
         is optional and used for formality

7. Similar to exit command,
    shell function can return an exit status by including an integer argument to the return command.
    i.e. return 0/1

8. String Expression, used to evaluate strings
  STRING, STRING is not null
  -n STRING, the length of STRING is greater than zero.
  -z STRING, the length of STRING is zero
  STRING1 == STRING2, STRING1 and STRING2 are equal
                      Note: STRING1 = STRING2 is applicable as well, but definitely not preferred
  STRING1 != STRING2, STRING1 and STRING2 are not equal
  Note: following expressions must be quoted
  STRING1 > STRING2, STRING1 sorts after STRING2
  STRING1 < STRING2, STRING1 sorts before STRING2

9. Integer Expressions
  integer1 -eq integer2, integer1 is equal to integer2
  integer1 -ne integer2, integer1 is not equal to integer2
  integer1 -le integer2, integer1 is less than or equal to integer2
  integer1 -lt integer2, integer1 is less than integer2
  integer1 -ge integer2, integer1 is greater than or equal to integer2
  integer1 -gt integer2, integer1 is greater than integer2

10. A more Modern Version of test expression (applicable only to bash)
  10.1 [[ ]], similar test expression(POSIX syntax),
              however, it also adds
              10.1.1 string =~ REGEX, regular expression mapping
              10.1.2 == operator, supports pattern matching the same way pathname expression does
                                  i.e. [[ $FILE == foo.* ]]
  10.2 (( )), designed for integers, used for arithmetic truth test
              return:
                true if the value inside (( )) non-zero !!!
                false, if the value inside (( )) is zero

11. logical operands
    -a, &&, logical AND
    -o, ||, logical OR
    !, logical NOT

Reading Keyboard Input
1. read [-options] [variable...]
  1.1 When reading the variables, they are implicitly declared
  1.2 If read receives fewer than the expected number, the extra variables are empty.
      If excessive amount of input is read, they will all end up in the final variable
      If no variables are listed after the read command, shell variable REPLY will be assigned as the input
  1.3 Useful options:
    -a, assign the input to array.
    -e, use ReadLine to handle input. This permits input editing in the same manner as command line.
    -p, display a prompt for input using the string prompt
    -r, raw mode, do not interpret backslash characters as esapts
    -s, silent mode, do not echo characters to the display as they are typed.
        This is useful when inputting passwords and confidential information.
    -t seconds, timeout, terminate input after seconds
    -u fd, use input from file descriptor fd, rather than standard input.

2. IFS, Internal Field Separator

3. The shell allows one or more variable assignments to take place immediately before a command.
   The effect of the assignment is temporary (only the duration of the command).
   i.e.
   IFS=":" read user pw uid gid name home shell <<< "$file_info"

4. <<< operator, indicates the "here string".
                 similar to here document which allow you to embed texts,
                 only shorter.

5. You can not Pipe read !!!
   read can not read stdIn, but can read stdOut

6. In Unix-like systems, pipelines are implemented by subshells,
    subshell copies environments but they can not alter the environment of their parent

Flow Control: Looping with while/until
1. While Loop syntax:
    while [[ condition ]]; do
      #statements
    done
    Note: while exits loop when condition is non-zero (logical true)

2. Until Loop syntax:
    until [[ condition ]]; do
      #statements
    done
  Note: until loop is similar to while loop, except that
        until exits loop when the condition is zero (logical false)

3. continue, break controls the loop

4. To redirect a file to the loop,
   we place the redirection operator after the done statement of the while loop

Troubleshooting
1. we can use echo command to print informations guiding debugging

2. for the debugging messages,
   we can send them to stdErr to separate them from normal output
   we also do not indent the lines containing the messages,
   so it is easier to find when it's time to remove them

3. to enable shell script built-in tracing:
  in the first Shebang line, add '-x' option

4. Enable tracing for a portion of script
   wrap the desired portion with:
   set -x
   set +x

5. For heavy duty debugging, use the "Bash Debugger"

Flow control branching with case
1. case statement syntax:

    case word in
      pattern )
        ;;
    esac

  Note:
  1.1 patterns are terminated with ')'
  1.2 default pattern is *
  1.3 to break out one particular case, we should use ';;&',
      which is the same as 'break' in loops

Positional Parameters
1. Accessing the command line:
  1.1 the default initialized command line parameters are $0~$9,
      they are global to the script/shell functions,
      and $0 is the full pathname of the "command"

  1.2 You can access more than nine parameters by using parameter expansion
      i.e. ${10}

  1.3 $#, will yield the number of (parameters-1), which represent the numb of arguments

2. shift, once it is called, it shifts the command line argument one step left, decrease the number of parameters by 1
   Note: $0 never change

3. Positional Parameter group expansion
  $*, Expands into the list of positional parameters, starting with 1
      When surrounded by double quotes,
      it expands into a double quoted string containing all of the positional parameters,
      each separated by the first character of the IFS(Interior Field Separator)
  $@, Expands into the list of positional parameters, starting with 1
      When surrounded by double quotes,
      it expands each positional parameter into a separate word surrounded by double quotes.
  Note: when not surrounded with " ", these two expansion are the same
        when surrounded with " ", $@ considers the original positional parameter, which makes it more useful

  
